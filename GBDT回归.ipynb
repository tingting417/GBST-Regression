{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   注意dataframe 类型数据iloc很慢，可以用apply函数尝试，或者替换成ndarray格式\n",
    "class DecisionTreeRegression():\n",
    "    def __init__(self,max_depth: int = None,min_samples_split:int = 5,\n",
    "         min_samples_leaf: int = 5,min_impurity_decrease: float =0.0):\n",
    "        '''\n",
    "        min_samples_split:  内部节点再划分所需最小样本数\n",
    "        min_samples_leaf:   叶子节点最少样本数 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝\n",
    "        分裂需要满足的最小增益\n",
    "        max_depth: 最大深度\n",
    "        min_impurity_decrease:分裂需要满足的最小增益\n",
    "        '''\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.nodes = 0  \n",
    "        self.tree = None\n",
    "        self.type_feature = None\n",
    "        self.index = None\n",
    "    def __MSE(self,y):\n",
    "        '''\n",
    "        :param data: \n",
    "        :param y: 目标数据\n",
    "        :return: MSE: 返回该分支的MSE\n",
    "        '''\n",
    "        ##  根据第一个公式\n",
    "        mean = np.mean(y)  \n",
    "        mse = np.sum((y-mean)**2)\n",
    "        return mse\n",
    "\n",
    "    def __typeFeature(self,X):\n",
    "        # 表示特征是否为连续还是离散\n",
    "        n_sample,n_feature = X.shape\n",
    "        self.type_feature = []\n",
    "        ####   特征属性小于10个，认为是离散型数据用0表示，连续性数据用1 表示\n",
    "        for f_idx in range(n_feature):\n",
    "            if len(np.unique(X[:, f_idx]))< 10:\n",
    "                self.type_feature.append(0)\n",
    "            else:\n",
    "                self.type_feature.append(1)\n",
    "        return self.type_feature\n",
    "                \n",
    "\n",
    "    def __binSplitData(self,X,y,index,f_idx,f_val):\n",
    "        ### att 数有数据在第f_idx的特征的所有属性,将不等于 f_val 分为一类，其余分为另一类\n",
    "        ####################    0: 离散类型特征二分方法 1:连续数据   ############################\n",
    "        att=X[:, f_idx]\n",
    "        \n",
    "        if self.type_feature[f_idx]== 0:\n",
    "            X_left = X[att == f_val]\n",
    "            X_right = X[att != f_val]\n",
    "            y_left = y[att == f_val]\n",
    "            y_right = y[att != f_val]\n",
    "            index_left = index[att == f_val]\n",
    "            index_right = index[att != f_val]\n",
    "        else:\n",
    "            X_left = X[att <= f_val]\n",
    "            X_right = X[att >f_val]\n",
    "            y_left = y[att <= f_val]\n",
    "            y_right = y[att > f_val]\n",
    "            index_left = index[att <= f_val]\n",
    "            index_right = index[att > f_val]\n",
    "           ## 切分点和样本点的索引\n",
    "        return X_left, X_right, y_left, y_right,index_left,index_right\n",
    "    \n",
    "    \n",
    "    def __bestSplit(self,X,y,index):\n",
    "        '''\n",
    "           \n",
    "        找到最佳分割特征与特征值\n",
    "        :param X\n",
    "        :return: best_f_idx  最佳分割特征 ， best_f_val 特征值\n",
    "         \n",
    "        '''\n",
    "        best_mse = self.__MSE(y)\n",
    "        n_sample,n_feature = X.shape\n",
    "        best_f_idx = None\n",
    "        best_f_val = np.mean(y)\n",
    "        ## 第一个终止条件： 当叶子节点中的样本数小于最小分割值，不再分割\n",
    "        if n_sample < self.min_samples_split:\n",
    "            return best_f_idx,best_f_val       \n",
    "        ##-------------------------通过不断二分的过程 寻找对于某个特征，的最佳分割点---------------------------\n",
    "        for f_idx in range(n_feature):\n",
    "        ##-------------------------如果该特征中的属性个数小于10，则认为是离散数据 type_feature = 0，否则else---------------------------\n",
    "\n",
    "            if self.type_feature[f_idx] == 0:\n",
    "                for f_val in np.unique(X[:, f_idx]):\n",
    "                    ## 当某个特征只有两个类别时，仅仅做一次左右子树的划分，不用重复操作\n",
    "                    if len(np.unique(X[:, f_idx]))== 2 and f_val == np.unique(X[:, f_idx])[0]:\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        X_left, X_right, y_left, y_right,index_left,index_right = self.__binSplitData(X,y,index,f_idx,f_val)\n",
    "\n",
    "                    ## 第二个终止条件： 分割后样本数据小于节点的最低样本数，则放弃分割   \n",
    "                        if len(index_left)<self.min_samples_leaf or len(index_right)<self.min_samples_leaf:\n",
    "                            continue\n",
    "                        mse = self.__MSE(y_left) + self.__MSE(y_right)\n",
    "                    ## 第三个终止条件，当分裂后的增益小于阈值后者大于目前最大增益\n",
    "                        if mse < self.min_impurity_decrease or mse > best_mse: \n",
    "                            continue\n",
    "                        else:\n",
    "                            ## 更新最大增益和最佳分裂位置\n",
    "                            best_mse = mse\n",
    "                            best_f_idx,best_f_val = f_idx,f_val\n",
    "        ##-------------------------     连续特征属性的二分 case = 1   ---------------------------\n",
    "            else:\n",
    "                for f_val in np.linspace(X[:, f_idx].min()+1,X[:, f_idx].max()-1,num=50):\n",
    "                        X_left, X_right, y_left, y_right,index_left,index_right = self.__binSplitData(X,y,index,f_idx,f_val)\n",
    "\n",
    "                    ## 第二个终止条件： 分割后样本数据小于节点的最低样本数，则放弃分割   \n",
    "                        if len(index_left)<self.min_samples_leaf or len(index_right)<self.min_samples_leaf:\n",
    "                            continue\n",
    "                        mse = self.__MSE(y_left) + self.__MSE(y_right)\n",
    "                         ## 第三个终止条件，当分裂后的增益小于阈值后者大于目前最大增益\n",
    "                        if mse < self.min_impurity_decrease or mse > best_mse: \n",
    "                            continue\n",
    "                        else:\n",
    "                            ## 更新最大增益和最佳分裂位置\n",
    "                            best_mse = mse\n",
    "                            best_f_idx,best_f_val = f_idx,f_val\n",
    "        return best_f_idx,best_f_val\n",
    "\n",
    "    def __CART(self,X,y,index):\n",
    "        '''\n",
    "        生成CART树\n",
    "        :param X： 特征数据\n",
    "        :param y: 目标数据\n",
    "        :return; CART 树\n",
    "        '''\n",
    "        best_f_idx, best_f_val = self.__bestSplit(X,y,index)\n",
    "        self.nodes += 1\n",
    "        \n",
    "       \n",
    "        # best_f_idx 为空表示不能接续划分，则该点为叶子结点  best_f_val\n",
    "        if best_f_idx is None:\n",
    "            return index\n",
    "        # 节点数超过最大深度的限制，也要返回叶节点，叶节点的值为当前数据中的目标值众数\n",
    "        if self.max_depth:\n",
    "            if self.nodes >= 2**self.max_depth:\n",
    "                return index\n",
    "        tree = dict()\n",
    "        tree['cut_f'] = best_f_idx\n",
    "        tree['cut_val'] = best_f_val\n",
    "        X_left, X_right, y_left, y_right,index_left,index_right = self.__binSplitData(X,y,index,best_f_idx,best_f_val)\n",
    "        tree['left_value'] = np.mean(y_left)\n",
    "        tree['right_value'] = np.mean(y_right)\n",
    "        tree['left'] = self.__CART(X_left,y_left,index_left)\n",
    "        tree['right'] = self.__CART(X_right,y_right,index_right)\n",
    "        return tree       \n",
    "   \n",
    "    \n",
    "    def fit(self,X,y,sample_weight = None):\n",
    "        '''\n",
    "        拟合模型，数据应该是 ndarray or series类型，dataframe通过 df.values转变成ndarray，不会报错\n",
    "        :param X: 特征数据\n",
    "        :param: y: 目标数据\n",
    "        :param: sample_weight\n",
    "        :return: None\n",
    "        '''\n",
    "        if sample_weight is None:\n",
    "            ## 使得每个数据的权值都是 1/len(X)    *len(X)是产生 len(X)个\n",
    "            sample_weight = np.array([1/len(X)] * len(X))\n",
    "        # 标记每个特征是离散还是连续，从而采用不同的二分方法\n",
    "        self.index = np.array(range(len(X)))\n",
    "        self.type_feature = self.__typeFeature(X) \n",
    "        self.tree = self.__CART(X,y,self.index)\n",
    "        return self.tree\n",
    "    def predict(self,X_test):\n",
    "        '''\n",
    "        数据类别预测\n",
    "        :param X_test:预测数据\n",
    "        :return: y_: 类别预测结果\n",
    "        '''\n",
    "\n",
    "        return np.array([self.__predict_one(x_test, self.tree) for x_test in X_test])\n",
    "    \n",
    "    def __predict_one(self,x_test,tree,label = None):\n",
    "        if isinstance(tree, dict):  # 非叶节点才做左右判断\n",
    "           \n",
    "            cut_f_idx, cut_val = tree['cut_f'], tree['cut_val']\n",
    "            if self.type_feature[cut_f_idx] == 0:\n",
    "                sub_tree = tree['left'] if x_test[cut_f_idx] == cut_val else tree['right']\n",
    "                label = tree['left_value'] if x_test[cut_f_idx] == cut_val else tree['right_value']\n",
    "            else:\n",
    "                sub_tree = tree['left'] if x_test[cut_f_idx] <= cut_val else tree['right']\n",
    "                label = tree['left_value'] if x_test[cut_f_idx] <=  cut_val else tree['right_value']\n",
    "            return self.__predict_one(x_test, sub_tree,label)\n",
    "        else:\n",
    "            return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDTRegression():\n",
    "    def __init__(self,estimators: int = 10, classifier = DecisionTreeRegression,step: float = 0.1):\n",
    "        self.estimators = estimators\n",
    "        self.weakLearner = classifier\n",
    "        self.step = step\n",
    "        self.trees = []\n",
    "        self.F_init = None\n",
    "        \n",
    "    def pseudoResiduals(self,y,predicted):\n",
    "        \n",
    "        rm = y - predicted\n",
    "        return rm\n",
    "    \n",
    "    def TerminalRegions(self,tree):\n",
    "        ###  找到每一个叶子节点内的数据，或者说找到叶子节点包含的区域\n",
    "        global Rm\n",
    "        for key, val in tree.items():\n",
    "            if key == 'left' or key =='right':\n",
    "                if isinstance(tree[key],dict):\n",
    "                    self.TerminalRegions(tree[key])\n",
    "                else:\n",
    "                    Rm.append(val)\n",
    "        return Rm\n",
    "    def findRegions(self,x,Rm):\n",
    "        for i in rangr(len(Rm)):\n",
    "            (x == Rm[s[1]]).sum()\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.F_init = np.mean(y)\n",
    "        ## step1 通过寻找损失函数最小是对应的来设置初值\n",
    "        F_before = np.array([np.mean(y)] * len(X)) \n",
    "        for m in range(self.estimators):\n",
    "            ##(a) 计算损失函数的负梯度值（也叫伪残差）\n",
    "            rm = self.pseudoResiduals(y,F_before)\n",
    "            ## (b) 建立学习器拟合以上残差，\n",
    "            tree_clf = self.weakLearner(max_depth = 4)\n",
    "            tree = tree_clf.fit(X, rm)\n",
    "            self.trees.append(tree_clf)\n",
    "            ## 并建立每个叶子节点最终区域\n",
    "            global Rm\n",
    "            Rm = []\n",
    "            Rm = self.TerminalRegions(tree)\n",
    "            Jm = len(Rm)\n",
    "            gamma_m = np.zeros(len(X)) \n",
    "            ## （c）通过最小化每个节点中数据的损失函数和\n",
    "            for j in range(Jm):\n",
    "                gamma_m[Rm[j]] += np.mean(rm[Rm[j]])\n",
    "            ##  (d)更新\n",
    "            Fm = F_before + self.step *  gamma_m\n",
    "            F_before = Fm\n",
    "            \n",
    "    def predict(self,x_test):\n",
    "        M = self.estimators\n",
    "        y_ = np.array([self.F_init] * len(x_test)) \n",
    "        for m in range(M):\n",
    "            a=  self.trees[m].predict(X_test)\n",
    "           # print('a.shape -----------------------------',a.shape,y_.shape)\n",
    "            y_ += self.step * self.trees[m].predict(X_test)\n",
    "        return y_      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:9.884889906420687\n",
      "sklearn acc:8.535771080365048\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn import datasets\n",
    "    import pandas as pd\n",
    "    import  numpy as np    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    house_dataset = datasets.load_boston();    #加载波士顿房价数据集\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(house_dataset.data)\n",
    "    Y = house_dataset.target\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    tree_clf = GBDTRegression(estimators = 100)\n",
    "    tree_clf.fit(X_train, Y_train)\n",
    "    Y_pred = tree_clf.predict(X_test)\n",
    "    print('acc:{}'.format(np.sum((Y_pred - Y_test)**2) / len(Y_test)))\n",
    "    del tree_clf\n",
    "    from sklearn.ensemble import GradientBoostingRegressor \n",
    "\n",
    "    tree_clf = GradientBoostingRegressor()\n",
    "\n",
    "    tree_clf.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = tree_clf.predict(X_test)\n",
    "    print('sklearn acc:{}'.format(np.sum((Y_pred - Y_test)**2) / len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:22.753196266573013\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.57891766, 35.35708878, 21.54893373, 14.50878362, 39.64773849,\n",
       "       13.21248439, 31.53645286, 29.13718817, 19.56760164, 23.28742579,\n",
       "       26.6419921 , 22.08780486, 24.61433953, 22.00347024, 29.56522168,\n",
       "       17.51526871, 20.93825286, 24.72178488, 11.1723631 , 20.73303011,\n",
       "       31.04410102, 16.22635696, 28.86828633, 19.47160032, 16.30586163,\n",
       "       27.4336788 , 42.25673537, 26.53003248, 27.48087024, 15.03062551,\n",
       "       31.55963188, 28.42785616, 26.89587815, 14.4454439 , 21.79319128,\n",
       "       23.38463672, 14.80201895, 20.5337216 , 23.25737652, 18.24862041,\n",
       "       32.7417942 , 20.8153666 , 26.18889394, 21.45996363, 14.47867669,\n",
       "        8.85596219, 43.44263105, 19.00668773, 15.82654107, 47.312889  ,\n",
       "       37.49322115, 13.21882953, 23.2191608 , 23.14380296, 23.59933316,\n",
       "       18.92533288, 20.10005454, 28.28696423,  7.92440958, 17.86400867,\n",
       "       26.49493648, 16.70176043, 18.09692757, 17.49296727, 25.23495782,\n",
       "       21.03396413, 26.51318059, 15.98838545, 16.46983476, 11.26964163,\n",
       "       22.791879  , 19.38083559, 23.63027861, 31.94811346, 20.80040474,\n",
       "       21.5633487 , 24.63195715, 22.34595076, 33.37844249, 17.78077847,\n",
       "        8.29128933, 17.27302258,  6.92912949, 17.61589624,  6.15839845,\n",
       "       34.88531461, 13.91153093, 16.69566446, 13.23746513, 24.56666879,\n",
       "       19.44987265, 25.57966188, 37.08611085,  8.87108686, 27.17193826,\n",
       "       16.61103321, 24.78446625, 18.14601792, 34.4340284 , 16.20546902,\n",
       "       26.15548344, 18.54641218])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.9, 36.2, 15.6, 13.4, 50. , 11.3, 37. , 24.4, 12.7, 19.7, 23.7,\n",
       "       22.2, 26.5, 24.4, 36. , 13.9, 19.4, 22. , 12.3, 20.2, 24. , 23.1,\n",
       "       50. , 19.5, 17.5, 29.9, 46. , 32. , 22.4, 17.1, 28.1, 50. , 25. ,\n",
       "       14.1, 17.1, 21.4, 14.8, 19.5, 23.2, 19.4, 50. , 18.4, 24.5, 16.6,\n",
       "       18.4, 11.7, 44.8, 18.3, 11.8, 43.5, 15. , 13.4, 23.2, 24.1, 23.3,\n",
       "       18.5, 21.7, 36.5,  8.4, 20.6, 24.8, 16.6, 18.7, 17.4, 26.6, 24.5,\n",
       "       24.5, 11.9, 19.3, 18. , 18.9, 19.3, 26.7, 33.2, 19.9, 16.5, 25. ,\n",
       "       24.7, 17.8,  8.5,  8.4, 23.8, 14.3, 19.1,  5. , 31. , 11.5, 19.8,\n",
       "       16.3, 34.9, 41.3, 23.6, 31.7, 10.5, 22. , 15.7, 22.6, 16.1, 36.1,\n",
       "       19.6, 20.5, 13.1])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(set(b)-set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [a,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [0, 3, 4, 5]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 == b[s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0 == b[s[1]]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
